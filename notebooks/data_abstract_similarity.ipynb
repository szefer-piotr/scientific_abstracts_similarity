{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar Abstract Search\n",
    "\n",
    "https://medium.com/@davidlfliang/intro-getting-started-with-text-embeddings-using-bert-9f8c3b98dee6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/projects/articles_similarity/scientific_abstracts_similarity/dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/Cornell-University/arxiv?dataset_version_number=208...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.37G/1.37G [04:39<00:00, 5.25MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/arxiv_dataset /root/.cache/kagglehub/datasets/Cornell-University/arxiv/versions/208\n"
     ]
    }
   ],
   "source": [
    "# Use kaggle API to download example data. arxiv apaper Abstracts and there is also arXive Dataset (4.5 GB)\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "# path = kagglehub.dataset_download(\"Cornell-University/arxiv\")\n",
    "\n",
    "# print(\"data/arxiv_dataset\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /root/.cache/kagglehub/datasets/Cornell-University/arxiv/versions/208/arxiv-metadata-oai-snapshot.json /home/piotr/projects/articles_similarity/scientific_abstracts_similarity/data/arxiv_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-large-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:  tensor([[  101,  1109,  3613,  3058, 17594, 15457,  1166,  1103, 16688,  3676,\n",
      "           119,   102]])\n",
      "Attention Mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Token Type IDs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Tokens: ['[CLS]', 'The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# from transformers import BertTokenizer\n",
    "\n",
    "# bert_tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# bert_inputs = bert_tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# print('Token IDs: ', bert_inputs['input_ids'])\n",
    "\n",
    "# attention_mask = bert_inputs['attention_mask']\n",
    "# print('Attention Mask: ', attention_mask)\n",
    "\n",
    "# token_type_ids = bert_inputs['token_type_ids']\n",
    "# print('Token Type IDs:', token_type_ids)\n",
    "\n",
    "# tokens = bert_tokenizer.convert_ids_to_tokens(bert_inputs['input_ids'][0])\n",
    "# print('Tokens:', tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert_inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the last hidden state (embedding): torch.Size([1, 12, 1024])\n",
      "Token: [CLS], Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.3982, -0.5164,  0.1184,  0.2094, -0.0663])\n",
      "Token: The, Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.5459, -0.9618,  0.1409, -0.1374, -0.1215])\n",
      "Token: quick, Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.1578,  0.3739, -0.2527, -0.0500,  0.7173])\n",
      "Token: brown, Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-1.0575, -0.4547,  0.0686, -0.6760,  0.7317])\n",
      "Token: fox, Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.1732, -0.2297, -0.7842,  0.0217,  0.0425])\n",
      "Token: jumps, Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.5367,  0.0404, -0.0642, -0.2768,  0.2793])\n",
      "Token: over, Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.4793, -0.4594, -0.0895, -0.7444,  0.3015])\n",
      "Token: the, Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.1132,  0.5350,  0.7333, -0.5768,  0.5068])\n",
      "Token: lazy, Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.1651,  0.8514, -0.1275,  0.1112,  0.4956])\n",
      "Token: dog, Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.1368,  0.5770, -0.6267,  0.0595, -0.1130])\n",
      "Token: ., Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.1039, -1.2749, -0.1801,  0.0774,  0.0065])\n",
      "Token: [SEP], Embedding Dimension:torch.Size([1024]),\n",
      "Embedding (first 5 components): tensor([-0.1040, -1.2749, -0.1801,  0.0775,  0.0065])\n"
     ]
    }
   ],
   "source": [
    "# from transformers import BertModel\n",
    "# import torch\n",
    "\n",
    "# model = BertModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**bert_inputs)\n",
    "\n",
    "# last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# print('Shape of the last hidden state (embedding):', last_hidden_states.shape)\n",
    "\n",
    "# tokens = bert_tokenizer.convert_ids_to_tokens(bert_inputs['input_ids'][0])\n",
    "# for token, embedding in zip(tokens, last_hidden_states[0]):\n",
    "#     print(f\"Token: {token}, Embedding Dimension:{embedding.shape},\\nEmbedding (first 5 components): {embedding[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models like SBERT (Sentence-BERT) are specialized in generating high-quality sentence embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Similarity Search\n",
    "\n",
    "### Handle 4.5 GB JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-large-cased'\n",
    "dataset_path = '../data/arxiv_papers/arxiv-metadata-oai-snapshot.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read one example line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0704.0001', 'submitter': 'Pavel Nadolsky', 'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\", 'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies', 'comments': '37 pages, 15 figures; published version', 'journal-ref': 'Phys.Rev.D76:013009,2007', 'doi': '10.1103/PhysRevD.76.013009', 'report-no': 'ANL-HEP-PR-07-12', 'categories': 'hep-ph', 'license': None, 'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n', 'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}], 'update_date': '2008-11-26', 'authors_parsed': [['Balázs', 'C.', ''], ['Berger', 'E. L.', ''], ['Nadolsky', 'P. M.', ''], ['Yuan', 'C. -P.', '']]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open the NDJSON file\n",
    "with open(dataset_path, 'r') as f:\n",
    "    # Read the first line\n",
    "    line = f.readline().strip()\n",
    "    # Parse the JSON object\n",
    "    data = json.loads(line)\n",
    "    print(data)  # Output the parsed JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read lines from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0704.0001', 'submitter': 'Pavel Nadolsky', 'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\", 'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies', 'comments': '37 pages, 15 figures; published version', 'journal-ref': 'Phys.Rev.D76:013009,2007', 'doi': '10.1103/PhysRevD.76.013009', 'report-no': 'ANL-HEP-PR-07-12', 'categories': 'hep-ph', 'license': None, 'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n', 'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}], 'update_date': '2008-11-26', 'authors_parsed': [['Balázs', 'C.', ''], ['Berger', 'E. L.', ''], ['Nadolsky', 'P. M.', ''], ['Yuan', 'C. -P.', '']]}\n",
      "{'id': '0704.0002', 'submitter': 'Louis Theran', 'authors': 'Ileana Streinu and Louis Theran', 'title': 'Sparsity-certifying Graph Decompositions', 'comments': 'To appear in Graphs and Combinatorics', 'journal-ref': None, 'doi': None, 'report-no': None, 'categories': 'math.CO cs.CG', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'abstract': '  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n', 'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 02:26:18 GMT'}, {'version': 'v2', 'created': 'Sat, 13 Dec 2008 17:26:00 GMT'}], 'update_date': '2008-12-13', 'authors_parsed': [['Streinu', 'Ileana', ''], ['Theran', 'Louis', '']]}\n",
      "{'id': '0704.0003', 'submitter': 'Hongjun Pan', 'authors': 'Hongjun Pan', 'title': 'The evolution of the Earth-Moon system based on the dark matter field\\n  fluid model', 'comments': '23 pages, 3 figures', 'journal-ref': None, 'doi': None, 'report-no': None, 'categories': 'physics.gen-ph', 'license': None, 'abstract': \"  The evolution of Earth-Moon system is described by the dark matter field\\nfluid model proposed in the Meeting of Division of Particle and Field 2004,\\nAmerican Physical Society. The current behavior of the Earth-Moon system agrees\\nwith this model very well and the general pattern of the evolution of the\\nMoon-Earth system described by this model agrees with geological and fossil\\nevidence. The closest distance of the Moon to Earth was about 259000 km at 4.5\\nbillion years ago, which is far beyond the Roche's limit. The result suggests\\nthat the tidal friction may not be the primary cause for the evolution of the\\nEarth-Moon system. The average dark matter field fluid constant derived from\\nEarth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts\\nthat the Mars's rotation is also slowing with the angular acceleration rate\\nabout -4.38 x 10^(-22) rad s^(-2).\\n\", 'versions': [{'version': 'v1', 'created': 'Sun, 1 Apr 2007 20:46:54 GMT'}, {'version': 'v2', 'created': 'Sat, 8 Dec 2007 23:47:24 GMT'}, {'version': 'v3', 'created': 'Sun, 13 Jan 2008 00:36:28 GMT'}], 'update_date': '2008-01-13', 'authors_parsed': [['Pan', 'Hongjun', '']]}\n",
      "{'id': '0704.0004', 'submitter': 'David Callan', 'authors': 'David Callan', 'title': 'A determinant of Stirling cycle numbers counts unlabeled acyclic\\n  single-source automata', 'comments': '11 pages', 'journal-ref': None, 'doi': None, 'report-no': None, 'categories': 'math.CO', 'license': None, 'abstract': '  We show that a determinant of Stirling cycle numbers counts unlabeled acyclic\\nsingle-source automata. The proof involves a bijection from these automata to\\ncertain marked lattice paths and a sign-reversing involution to evaluate the\\ndeterminant.\\n', 'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 03:16:14 GMT'}], 'update_date': '2007-05-23', 'authors_parsed': [['Callan', 'David', '']]}\n",
      "{'id': '0704.0005', 'submitter': 'Alberto Torchinsky', 'authors': 'Wael Abu-Shammala and Alberto Torchinsky', 'title': 'From dyadic $\\\\Lambda_{\\\\alpha}$ to $\\\\Lambda_{\\\\alpha}$', 'comments': None, 'journal-ref': 'Illinois J. Math. 52 (2008) no.2, 681-689', 'doi': None, 'report-no': None, 'categories': 'math.CA math.FA', 'license': None, 'abstract': '  In this paper we show how to compute the $\\\\Lambda_{\\\\alpha}$ norm, $\\\\alpha\\\\ge\\n0$, using the dyadic grid. This result is a consequence of the description of\\nthe Hardy spaces $H^p(R^N)$ in terms of dyadic and special atoms.\\n', 'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 18:09:58 GMT'}], 'update_date': '2013-10-15', 'authors_parsed': [['Abu-Shammala', 'Wael', ''], ['Torchinsky', 'Alberto', '']]}\n",
      "{'id': '0704.0006', 'submitter': 'Yue Hin Pong', 'authors': 'Y. H. Pong and C. K. Law', 'title': 'Bosonic characters of atomic Cooper pairs across resonance', 'comments': '6 pages, 4 figures, accepted by PRA', 'journal-ref': None, 'doi': '10.1103/PhysRevA.75.043613', 'report-no': None, 'categories': 'cond-mat.mes-hall', 'license': None, 'abstract': '  We study the two-particle wave function of paired atoms in a Fermi gas with\\ntunable interaction strengths controlled by Feshbach resonance. The Cooper pair\\nwave function is examined for its bosonic characters, which is quantified by\\nthe correction of Bose enhancement factor associated with the creation and\\nannihilation composite particle operators. An example is given for a\\nthree-dimensional uniform gas. Two definitions of Cooper pair wave function are\\nexamined. One of which is chosen to reflect the off-diagonal long range order\\n(ODLRO). Another one corresponds to a pair projection of a BCS state. On the\\nside with negative scattering length, we found that paired atoms described by\\nODLRO are more bosonic than the pair projected definition. It is also found\\nthat at $(k_F a)^{-1} \\\\ge 1$, both definitions give similar results, where more\\nthan 90% of the atoms occupy the corresponding molecular condensates.\\n', 'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 04:24:59 GMT'}], 'update_date': '2015-05-13', 'authors_parsed': [['Pong', 'Y. H.', ''], ['Law', 'C. K.', '']]}\n",
      "{'id': '0704.0007', 'submitter': 'Alejandro Corichi', 'authors': 'Alejandro Corichi, Tatjana Vukasinac and Jose A. Zapata', 'title': 'Polymer Quantum Mechanics and its Continuum Limit', 'comments': '16 pages, no figures. Typos corrected to match published version', 'journal-ref': 'Phys.Rev.D76:044016,2007', 'doi': '10.1103/PhysRevD.76.044016', 'report-no': 'IGPG-07/03-2', 'categories': 'gr-qc', 'license': None, 'abstract': '  A rather non-standard quantum representation of the canonical commutation\\nrelations of quantum mechanics systems, known as the polymer representation has\\ngained some attention in recent years, due to its possible relation with Planck\\nscale physics. In particular, this approach has been followed in a symmetric\\nsector of loop quantum gravity known as loop quantum cosmology. Here we explore\\ndifferent aspects of the relation between the ordinary Schroedinger theory and\\nthe polymer description. The paper has two parts. In the first one, we derive\\nthe polymer quantum mechanics starting from the ordinary Schroedinger theory\\nand show that the polymer description arises as an appropriate limit. In the\\nsecond part we consider the continuum limit of this theory, namely, the reverse\\nprocess in which one starts from the discrete theory and tries to recover back\\nthe ordinary Schroedinger quantum mechanics. We consider several examples of\\ninterest, including the harmonic oscillator, the free particle and a simple\\ncosmological model.\\n', 'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 04:27:22 GMT'}, {'version': 'v2', 'created': 'Wed, 22 Aug 2007 22:42:11 GMT'}], 'update_date': '2008-11-26', 'authors_parsed': [['Corichi', 'Alejandro', ''], ['Vukasinac', 'Tatjana', ''], ['Zapata', 'Jose A.', '']]}\n",
      "{'id': '0704.0008', 'submitter': 'Damian Swift', 'authors': 'Damian C. Swift', 'title': 'Numerical solution of shock and ramp compression for general material\\n  properties', 'comments': 'Minor corrections', 'journal-ref': 'Journal of Applied Physics, vol 104, 073536 (2008)', 'doi': '10.1063/1.2975338', 'report-no': 'LA-UR-07-2051, LLNL-JRNL-410358', 'categories': 'cond-mat.mtrl-sci', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'abstract': '  A general formulation was developed to represent material models for\\napplications in dynamic loading. Numerical methods were devised to calculate\\nresponse to shock and ramp compression, and ramp decompression, generalizing\\nprevious solutions for scalar equations of state. The numerical methods were\\nfound to be flexible and robust, and matched analytic results to a high\\naccuracy. The basic ramp and shock solution methods were coupled to solve for\\ncomposite deformation paths, such as shock-induced impacts, and shock\\ninteractions with a planar interface between different materials. These\\ncalculations capture much of the physics of typical material dynamics\\nexperiments, without requiring spatially-resolving simulations. Example\\ncalculations were made of loading histories in metals, illustrating the effects\\nof plastic work on the temperatures induced in quasi-isentropic and\\nshock-release experiments, and the effect of a phase transition.\\n', 'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 04:47:20 GMT'}, {'version': 'v2', 'created': 'Thu, 10 Apr 2008 08:42:28 GMT'}, {'version': 'v3', 'created': 'Tue, 1 Jul 2008 18:54:28 GMT'}], 'update_date': '2009-02-05', 'authors_parsed': [['Swift', 'Damian C.', '']]}\n",
      "{'id': '0704.0009', 'submitter': 'Paul Harvey', 'authors': 'Paul Harvey, Bruno Merin, Tracy L. Huard, Luisa M. Rebull, Nicholas\\n  Chapman, Neal J. Evans II, Philip C. Myers', 'title': 'The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The\\n  Serpens YSO Population As Observed With IRAC and MIPS', 'comments': None, 'journal-ref': 'Astrophys.J.663:1149-1173,2007', 'doi': '10.1086/518646', 'report-no': None, 'categories': 'astro-ph', 'license': None, 'abstract': \"  We discuss the results from the combined IRAC and MIPS c2d Spitzer Legacy\\nobservations of the Serpens star-forming region. In particular we present a set\\nof criteria for isolating bona fide young stellar objects, YSO's, from the\\nextensive background contamination by extra-galactic objects. We then discuss\\nthe properties of the resulting high confidence set of YSO's. We find 235 such\\nobjects in the 0.85 deg^2 field that was covered with both IRAC and MIPS. An\\nadditional set of 51 lower confidence YSO's outside this area is identified\\nfrom the MIPS data combined with 2MASS photometry. We describe two sets of\\nresults, color-color diagrams to compare our observed source properties with\\nthose of theoretical models for star/disk/envelope systems and our own modeling\\nof the subset of our objects that appear to be star+disks. These objects\\nexhibit a very wide range of disk properties, from many that can be fit with\\nactively accreting disks to some with both passive disks and even possibly\\ndebris disks. We find that the luminosity function of YSO's in Serpens extends\\ndown to at least a few x .001 Lsun or lower for an assumed distance of 260 pc.\\nThe lower limit may be set by our inability to distinguish YSO's from\\nextra-galactic sources more than by the lack of YSO's at very low luminosities.\\nA spatial clustering analysis shows that the nominally less-evolved YSO's are\\nmore highly clustered than the later stages and that the background\\nextra-galactic population can be fit by the same two-point correlation function\\nas seen in other extra-galactic studies. We also present a table of matches\\nbetween several previous infrared and X-ray studies of the Serpens YSO\\npopulation and our Spitzer data set.\\n\", 'versions': [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:41:34 GMT'}], 'update_date': '2010-03-18', 'authors_parsed': [['Harvey', 'Paul', ''], ['Merin', 'Bruno', ''], ['Huard', 'Tracy L.', ''], ['Rebull', 'Luisa M.', ''], ['Chapman', 'Nicholas', ''], ['Evans', 'Neal J.', 'II'], ['Myers', 'Philip C.', '']]}\n",
      "{'id': '0704.0010', 'submitter': 'Sergei Ovchinnikov', 'authors': 'Sergei Ovchinnikov', 'title': 'Partial cubes: structures, characterizations, and constructions', 'comments': '36 pages, 17 figures', 'journal-ref': None, 'doi': None, 'report-no': None, 'categories': 'math.CO', 'license': None, 'abstract': \"  Partial cubes are isometric subgraphs of hypercubes. Structures on a graph\\ndefined by means of semicubes, and Djokovi\\\\'{c}'s and Winkler's relations play\\nan important role in the theory of partial cubes. These structures are employed\\nin the paper to characterize bipartite graphs and partial cubes of arbitrary\\ndimension. New characterizations are established and new proofs of some known\\nresults are given.\\n  The operations of Cartesian product and pasting, and expansion and\\ncontraction processes are utilized in the paper to construct new partial cubes\\nfrom old ones. In particular, the isometric and lattice dimensions of finite\\npartial cubes obtained by means of these operations are calculated.\\n\", 'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 05:10:16 GMT'}], 'update_date': '2007-05-23', 'authors_parsed': [['Ovchinnikov', 'Sergei', '']]}\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "with open(dataset_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        texts.append(data)\n",
    "        print(data)\n",
    "        if len(texts) > 9:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0704.0004',\n",
       " 'submitter': 'David Callan',\n",
       " 'authors': 'David Callan',\n",
       " 'title': 'A determinant of Stirling cycle numbers counts unlabeled acyclic\\n  single-source automata',\n",
       " 'comments': '11 pages',\n",
       " 'journal-ref': None,\n",
       " 'doi': None,\n",
       " 'report-no': None,\n",
       " 'categories': 'math.CO',\n",
       " 'license': None,\n",
       " 'abstract': '  We show that a determinant of Stirling cycle numbers counts unlabeled acyclic\\nsingle-source automata. The proof involves a bijection from these automata to\\ncertain marked lattice paths and a sign-reversing involution to evaluate the\\ndeterminant.\\n',\n",
       " 'versions': [{'version': 'v1', 'created': 'Sat, 31 Mar 2007 03:16:14 GMT'}],\n",
       " 'update_date': '2007-05-23',\n",
       " 'authors_parsed': [['Callan', 'David', '']]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def get_sentence_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    sentence_embedding = torch.mean(last_hidden_states, dim=1).numpy()\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [get_sentence_embedding(text['abstract']) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(query_embedding, np.vstack(embeddings[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float32(0.9335567), np.float32(0.88754284), np.float32(0.8645277), np.float32(0.84983355), np.float32(0.83770466), np.float32(0.788833), np.float32(0.7758506), np.float32(0.7589118), np.float32(0.7367904)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(similarities[0], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query text: Calculation of prompt diphoton production cross sections at Tevatron and\n",
      "  LHC energies\n",
      "Similarity with 'Sparsity-certifying Graph Decompositions': 0.7367904186248779\n",
      "Similarity with 'The evolution of the Earth-Moon system based on the dark matter field\n",
      "  fluid model': 0.7589117884635925\n",
      "Similarity with 'A determinant of Stirling cycle numbers counts unlabeled acyclic\n",
      "  single-source automata': 0.7758505940437317\n",
      "Similarity with 'From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\alpha}$': 0.7888330221176147\n",
      "Similarity with 'Bosonic characters of atomic Cooper pairs across resonance': 0.8377046585083008\n",
      "Similarity with 'Polymer Quantum Mechanics and its Continuum Limit': 0.8498335480690002\n",
      "Similarity with 'Numerical solution of shock and ramp compression for general material\n",
      "  properties': 0.864527702331543\n",
      "Similarity with 'The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The\n",
      "  Serpens YSO Population As Observed With IRAC and MIPS': 0.8875428438186646\n",
      "Similarity with 'Partial cubes: structures, characterizations, and constructions': 0.9335566759109497\n"
     ]
    }
   ],
   "source": [
    "# Print query text\n",
    "print (f\"Query text: {texts[0]['title']}\")\n",
    "\n",
    "# Print similarities\n",
    "for i, text in enumerate(texts[1:]):\n",
    "    print(f\"Similarity with '{text['title']}': {similarities[0][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
